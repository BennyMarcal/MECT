{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T17:50:16.911765Z",
     "start_time": "2024-11-24T17:50:16.893182Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, log_loss, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e681ffadd1db3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T17:34:52.949580Z",
     "start_time": "2024-11-24T17:34:52.935917Z"
    }
   },
   "outputs": [],
   "source": [
    "X_raw = np.load(\"dataset/X.npy\")\n",
    "\n",
    "y_raw = np.load(\"dataset/Y.npy\")\n",
    "# transform the y into a (m, 1) matrix\n",
    "y_raw = np.argmax(y_raw,axis=1).reshape(y_raw.shape[0], 1)\n",
    "\n",
    "n_classes = np.unique(y_raw).size\n",
    "\n",
    "print(\"X shape is \", X_raw.shape, \"\", sep=\"\")\n",
    "print(\"y shape is \", y_raw.shape, \"\", sep=\"\")\n",
    "print(\"Number of classes is\", n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d519408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pltImage(img, grid=None, title=None, figsize=(5,5)):\n",
    "    # Plots one or multiple images\n",
    "    #  - one image if grid is none\n",
    "    #  - a grid of images if grid is not null, it must be a tuple (y, x)\n",
    "\n",
    "    if grid == None:\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        if title:\n",
    "            plt.title(title)\n",
    "        plt.axis('off')\n",
    "    else:\n",
    "        if grid[0]*grid[1] < len(img):\n",
    "            raise ValueError('Insufficient grid size')\n",
    "        fig, axes = plt.subplots(grid[0], grid[1], figsize=figsize)\n",
    "        ax = axes.flat\n",
    "        for i in range(len(img)):\n",
    "            ax[i].imshow(img[i], cmap='gray', vmin=0, vmax=1)\n",
    "            ax[i].axis('off')\n",
    "            if title:\n",
    "                ax[i].set_title(title[i])\n",
    "        plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# test func pltImage\n",
    "pltImage(X_raw[0], title='X_raw[0]')\n",
    "pltImage(X_raw[0:10], grid=(2,5), figsize=(10,5), title=[f\"Raw {i}\" for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdf2f0e86a07e6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T17:34:53.058026Z",
     "start_time": "2024-11-24T17:34:53.045511Z"
    }
   },
   "outputs": [],
   "source": [
    "# augment raw data\n",
    "def augment(X, y, rotation = [0, 0], scaling = [1, 1], mult=2):\n",
    "    # augments a image by getting random mutations of it\n",
    "    # the number of mutations is given by mult*mult\n",
    "\n",
    "    (h, w) = X[0].shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    new_X = []\n",
    "    new_y = []\n",
    "\n",
    "    for _ in range(mult): # angle\n",
    "        for _ in range(mult): # scale\n",
    "            for i in range(X.shape[0]):\n",
    "                M = cv2.getRotationMatrix2D(center, random.uniform(*rotation), random.uniform(*scaling))\n",
    "                transformed = cv2.warpAffine(X[i], M, (w, h), borderMode=cv2.BORDER_REPLICATE)\n",
    "                new_X.append(transformed)\n",
    "                new_y.append(y[i])\n",
    "\n",
    "    return np.array(new_X), np.array(new_y)\n",
    "\n",
    "# test augment (run multiple times for different outputs)\n",
    "X, y = augment(X_raw[:1], y_raw[:1], rotation=[-45, 45], scaling=[0.5, 1.5], mult=3)\n",
    "pltImage(X, grid=(3,3), figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d7e74b0715345e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T17:34:53.106396Z",
     "start_time": "2024-11-24T17:34:53.103141Z"
    }
   },
   "outputs": [],
   "source": [
    "# transform raw data into edges\n",
    "def get_edges(X):\n",
    "    X_edges = (X*255.0).astype(np.uint8)\n",
    "    for i in range(len(X_edges)):\n",
    "        X_edges[i] = cv2.GaussianBlur(X_edges[i], (5, 5), 0)\n",
    "        X_edges[i] = cv2.Canny(X_edges[i], 50, 150)\n",
    "    return X_edges\n",
    "\n",
    "# test func edges\n",
    "X = get_edges(X_raw[0:5])\n",
    "pltImage([x for pair in zip(X_raw[0:5], X) for x in pair], grid=(5, 2), figsize=(5,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc3951cfa60f0a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T17:34:53.224361Z",
     "start_time": "2024-11-24T17:34:53.218131Z"
    }
   },
   "outputs": [],
   "source": [
    "# divide X by corresponding y class\n",
    "def splitXbyClass(X, y):\n",
    "    new_X = [[] for i in range(np.unique(y).size)] # create array of arrays of size 10\n",
    "    for i in range(X.shape[0]):\n",
    "        _y = y[i][0]\n",
    "        new_X[_y].append(X[i])\n",
    "    return new_X\n",
    "\n",
    "# test the function\n",
    "X = splitXbyClass(X_raw, y_raw)\n",
    "imgs = []\n",
    "for i in range(10):\n",
    "    print(f\"Class {i} has {len(X[i])} images\")\n",
    "    imgs.append(X[i][0])\n",
    "pltImage(imgs, grid=(2,5), title=[str(i) for i in range(10)], figsize=(10,5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaac7a2904053b7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T17:34:53.161523Z",
     "start_time": "2024-11-24T17:34:53.157280Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_train_test_split(X_classes, train_ratio=0.8):\n",
    "    X_train, y_train, X_test, y_test = [], [], [], []\n",
    "\n",
    "    for i, c in enumerate(X_classes):\n",
    "        size = int(len(c)*train_ratio)\n",
    "        X_train.extend(c[0:size])\n",
    "        y_train.extend([i] * size)\n",
    "        X_test.extend(c[size:])\n",
    "        y_test.extend([i] * (len(c) - size))\n",
    "\n",
    "    # make sure y matrices are (n, 1)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    y_train = y_train.reshape(y_train.shape[0], 1)\n",
    "    y_test = y_test.reshape(y_test.shape[0], 1)\n",
    "\n",
    "    return np.array(X_train), y_train, np.array(X_test), y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb72848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(a):\n",
    "    return a.reshape(a.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6904a4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of Logistic Regression by hand\n",
    "def sigmoid(x):\n",
    "    epsilon = 1.0e-15\n",
    "    x = np.clip(x, -500, 500)\n",
    "    return np.clip(1/(1+np.exp(-x)), 0 + epsilon,  1 - epsilon)\n",
    "def logisticRegression(X, y, num_iterations, learning_rate):\n",
    "    m, n = X.shape\n",
    "    theta = np.zeros((n, 1))\n",
    "    b = 0\n",
    "    cost_history = []\n",
    "    for i in range(num_iterations):\n",
    "        h = sigmoid(np.dot(X, theta)) # forward pass\n",
    "        cost = 1/m * np.sum(-y * np.log(h) - (1 - y) * np.log(1 - h)) # cost calculation\n",
    "        grad = (1/m) * np.dot(X.T, (h - y)) # backwards pass\n",
    "        theta -= learning_rate * grad # update weights and bias\n",
    "        cost_history += [cost]\n",
    "        # print(\"\\rCost (\",i,\"):\", cost_history[-1], end=\"\")\n",
    "    return theta, cost_history\n",
    "def logisticRegressionReg(X, y, num_iterations, learning_rate, reg_strength):\n",
    "    m, n = X.shape\n",
    "    theta = np.zeros((n, 1))\n",
    "    b = 0\n",
    "    cost_history = []\n",
    "    for i in range(num_iterations):\n",
    "        # forward pass\n",
    "        h = sigmoid(np.dot(X, theta) + b) # forward pass\n",
    "        # cost calculation with regularization\n",
    "        reg_term = (reg_strength / (2*m)) * np.sum(np.square(theta))\n",
    "        cost = 1/m * np.sum(-y * np.log(h) - (1 - y) * np.log(1 - h)) + reg_term # cost calculation\n",
    "        # backward pass\n",
    "        grad = (1/m) * np.dot(X.T, (h - y)) + (reg_strength/m)*theta # backwards pass\n",
    "        db = (1/m) * np.sum(h - y)\n",
    "        # update weight and bias\n",
    "        theta -= learning_rate * grad # update weights and bias\n",
    "        b -= learning_rate * db\n",
    "        # track cost history\n",
    "        cost_history += [cost]\n",
    "        # print(\"\\rCost (\",i,\"):\", cost_history[-1], end=\"\")\n",
    "    return theta, cost_history\n",
    "def oneVsAllLogisticRegression(X, y, num_iterations, learning_rate, regularization_rate=0):\n",
    "    m, n = X.shape\n",
    "    k = (np.min(y), np.max(y))\n",
    "    # print(k)\n",
    "    all_theta = []\n",
    "    all_cost = []\n",
    "    for i in range(k[0], k[1]+1):\n",
    "        # print(\"K\",i)\n",
    "        if regularization_rate==0:\n",
    "            theta, cost_history = logisticRegression(X, np.where(y == i, 1, 0), num_iterations, learning_rate)\n",
    "        else:\n",
    "            theta, cost_history = logisticRegressionReg(X, np.where(y == i, 1, 0), num_iterations, learning_rate, regularization_rate)\n",
    "        all_theta.append(theta)\n",
    "        all_cost.extend(cost_history)\n",
    "        # print(\"\")\n",
    "    return all_theta, all_cost\n",
    "def predictOneVsAllLogisticRegression(all_theta, X):\n",
    "    predictions = np.dot(X, all_theta)\n",
    "    return np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c8ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Custom Logistic Regression implementation (With raw data)\n",
    "X_train, y_train, X_test, y_test = create_train_test_split(splitXbyClass(X_raw, y_raw), train_ratio=0.8)\n",
    "lr_all_theta1, lr_all_cost1 = oneVsAllLogisticRegression(reshape(X_train), y_train,  1000, 0.01, 0)\n",
    "\n",
    "predict = predictOneVsAllLogisticRegression(lr_all_theta1, reshape(X_train))\n",
    "print(\"Test 1 Pred Training: \", sum(predict==y_train)[0]/len(y_train)*100, \"%\")\n",
    "predict = predictOneVsAllLogisticRegression(lr_all_theta1, reshape(X_test))\n",
    "print(\"Test 1 Pred Test: \", sum(predict==y_test)[0]/len(y_test)*100, \"%\")\n",
    "plt.plot(lr_all_cost1)\n",
    "plt.show()\n",
    "\n",
    "# Test 2: Custom Logistic Regression implementation (With edges data)\n",
    "X_train, y_train, X_test, y_test = create_train_test_split(splitXbyClass(get_edges(X_raw), y_raw), train_ratio=0.8)\n",
    "lr_all_theta2, lr_all_cost2 = oneVsAllLogisticRegression(reshape(X_train), y_train,  1000, 0.01, 0.1)\n",
    "\n",
    "predict = predictOneVsAllLogisticRegression(lr_all_theta2, reshape(X_train))\n",
    "print(\"Test 2 Pred Training: \", sum(predict==y_train)[0]/len(y_train)*100, \"%\")\n",
    "predict = predictOneVsAllLogisticRegression(lr_all_theta2, reshape(X_test))\n",
    "print(\"Test 2 Pred Test: \", sum(predict==y_test)[0]/len(y_test)*100, \"%\")\n",
    "plt.plot(lr_all_cost2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf40a5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Logistic Regression (With raw data)\n",
    "X_train, y_train, X_test, y_test = create_train_test_split(splitXbyClass(X_raw, y_raw), train_ratio=0.9)\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(reshape(X_train), y_train.ravel())\n",
    "\n",
    "# accuracy analises\n",
    "y_pred = model.predict(reshape(X_train))\n",
    "a = accuracy_score(y_train.ravel(), y_pred)\n",
    "print(f\"Accuracy on training: {a * 100:.2f}%\")\n",
    "y_pred = model.predict(reshape(X_test))\n",
    "a = accuracy_score(y_test.ravel(), y_pred)\n",
    "print(f\"Accuracy on test: {a * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2a3fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Logistic Regression (With edge detection)\n",
    "X = get_edges(X_raw)\n",
    "X_train, y_train, X_test, y_test = create_train_test_split(splitXbyClass(X, y_raw), train_ratio=0.9)\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(reshape(X_train), y_train.ravel())\n",
    "\n",
    "# accuracy analises\n",
    "y_pred = model.predict(reshape(X_train))\n",
    "a = accuracy_score(y_train.ravel(), y_pred)\n",
    "print(f\"Accuracy on training: {a * 100:.2f}%\")\n",
    "y_pred = model.predict(reshape(X_test))\n",
    "a = accuracy_score(y_test.ravel(), y_pred)\n",
    "print(f\"Accuracy on test: {a * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a61e2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Logistic Regression (With augmentation)\n",
    "X, y = augment(X_raw, y_raw, [-10, 10], [0.8, 1.2], 2)\n",
    "X_train, y_train, X_test, y_test = create_train_test_split(splitXbyClass(X, y), train_ratio=0.9)\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(reshape(X_train), y_train.ravel())\n",
    "\n",
    "# accuracy analises\n",
    "y_pred = model.predict(reshape(X_train))\n",
    "a = accuracy_score(y_train.ravel(), y_pred)\n",
    "print(f\"Accuracy on training: {a * 100:.2f}%\")\n",
    "y_pred = model.predict(reshape(X_test))\n",
    "a = accuracy_score(y_test.ravel(), y_pred)\n",
    "print(f\"Accuracy on test: {a * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8ab15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Logistic Regression (With edge detection and augmentation)\n",
    "X, y = augment(X_raw, y_raw, [-10, 10], [0.8, 1.2], 3)\n",
    "X = get_edges(X)\n",
    "X_train, y_train, X_test, y_test = create_train_test_split(splitXbyClass(X, y), train_ratio=0.9)\n",
    "model = LogisticRegression(max_iter=1000, C=0.1, solver='lbfgs')\n",
    "model.fit(reshape(X_train), y_train.ravel())\n",
    "\n",
    "# accuracy analises\n",
    "y_pred = model.predict(reshape(X_train))\n",
    "a = accuracy_score(y_train.ravel(), y_pred)\n",
    "print(f\"Accuracy on training: {a * 100:.2f}%\")\n",
    "y_pred = model.predict(reshape(X_test))\n",
    "a = accuracy_score(y_test.ravel(), y_pred)\n",
    "print(f\"Accuracy on test: {a * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f66c67e9046274c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T17:38:56.586019Z",
     "start_time": "2024-11-24T17:37:25.206348Z"
    }
   },
   "outputs": [],
   "source": [
    "# Grid search\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'solver': ['lbfgs']\n",
    "}\n",
    "model = LogisticRegression(max_iter=100)\n",
    "grid_model = GridSearchCV(estimator=model, cv=5, scoring='accuracy', param_grid=param_grid)\n",
    "\n",
    "X_train, y_train, X_test, y_test = create_train_test_split(splitXbyClass(X_raw, y_raw), train_ratio=0.9)\n",
    "grid_model.fit(X_train.reshape(X_train.shape[0], -1), y_train.ravel())\n",
    "\n",
    "# Best parameters and best cross-validated score\n",
    "print(\"Best parameters:\", grid_model.best_params_)\n",
    "print(\"Best cross-validated score:\", grid_model.best_score_)\n",
    "\n",
    "# Test set evaluation\n",
    "best_model = grid_model.best_estimator_\n",
    "y_test_pred = best_model.predict(reshape(X_test))\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test set accuracy:\", test_accuracy)\n",
    "\n",
    "results = grid_model.cv_results_\n",
    "plt.plot(param_grid['C'], grid_model.cv_results_['mean_test_score'])\n",
    "plt.plot(param_grid['C'], grid_model.cv_results_['mean_test_score'])\n",
    "plt.xscale('log')\n",
    "plt.xlabel('C (Inverse of Regularization Strength)')\n",
    "plt.ylabel('Mean Cross-Validated Accuracy')\n",
    "plt.title('Grid Search Results for Logistic Regression')\n",
    "\n",
    "# Evaluate\n",
    "train_accuracy = grid_model.score(X_train.reshape(X_train.shape[0], -1), y_train)\n",
    "test_accuracy = grid_model.score(X_test.reshape(X_test.shape[0], -1), y_test)\n",
    "print(\"\\nTrain Accuracy:\", round(train_accuracy, 4), \"%\")\n",
    "print(\"Test Accuracy:\", round(test_accuracy, 4), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f3c3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix of the best Logistic Regression found\n",
    "y_test_pred = best_model.predict(reshape(X_test))\n",
    "cm = confusion_matrix(y_test.ravel(), y_test_pred, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=range(10))\n",
    "disp.plot(cmap=plt.cm.Blues, values_format=\".0%\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e35844",
   "metadata": {},
   "source": [
    "# Using TensorFow/Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47da203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No hidden layers, similar to logistic regression\n",
    "X_train, y_train, X_temp, y_temp = create_train_test_split(splitXbyClass(X_raw, y_raw), train_ratio=0.8)\n",
    "X_val, y_val, X_test, y_test = create_train_test_split(splitXbyClass(X_temp, y_temp), train_ratio=0.5)\n",
    "model = Sequential([\n",
    "    Dense(10, activation='softmax')  # Output layer for multi-class classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(reshape(X_train), y_train, epochs=500, batch_size=32, validation_data=(reshape(X_val), y_val))\n",
    "\n",
    "loss, accuracy = model.evaluate(reshape(X_train), y_train)\n",
    "print(f\"Train Accuracy: {accuracy * 100:.2f}%\")\n",
    "loss, accuracy = model.evaluate(reshape(X_test), y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history.get('val_loss')  # Will exist if validation data is used\n",
    "# Plot the loss\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(loss, label='Training Loss')\n",
    "\n",
    "if val_loss:\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df048de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple nn with two hidden layers\n",
    "X_train, y_train, X_temp, y_temp = create_train_test_split(splitXbyClass(X_raw, y_raw), train_ratio=0.8)\n",
    "X_val, y_val, X_test, y_test = create_train_test_split(splitXbyClass(X_temp, y_temp), train_ratio=0.5)\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu'),  # \n",
    "    Dense(64, activation='relu'),  # \n",
    "    Dense(10, activation='softmax')  # Output layer for multi-class classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(reshape(X_train), y_train, epochs=100, batch_size=32, validation_data=(reshape(X_val), y_val))\n",
    "\n",
    "loss, accuracy = model.evaluate(reshape(X_train), y_train)\n",
    "print(f\"Train Accuracy: {accuracy * 100:.2f}%\")\n",
    "loss, accuracy = model.evaluate(reshape(X_test), y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history.get('val_loss')  # Will exist if validation data is used\n",
    "# Plot the loss\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(loss, label='Training Loss')\n",
    "\n",
    "if val_loss:\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e924bd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two hidden layer with real-time data augmentation\n",
    "# (80%, 10%, 10%)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "X_train, y_train, X_temp, y_temp = create_train_test_split(splitXbyClass(X_raw, y_raw), train_ratio=0.8)\n",
    "X_val, y_val, X_test, y_test = create_train_test_split(splitXbyClass(X_temp, y_temp), train_ratio=0.5)\n",
    "X_train = X_train.reshape(X_train.shape[0], 64, 64, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], 64, 64, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 64, 64, 1)\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(64, 64, 1)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),  # Hidden layer with 128 neurons\n",
    "    Dense(n_classes, activation='softmax')  # Output layer for multi-class classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# less randomness because of model simplicity\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,         # Randomly rotate images\n",
    "    # width_shift_range=0.1,     # Randomly shift images horizontally\n",
    "    # height_shift_range=0.1,    # Randomly shift images vertically\n",
    "    # shear_range=0.2,           # Shear transformations\n",
    "    zoom_range=0.2,            # Random zoom\n",
    "    fill_mode='nearest'        # Fill in pixels after transformations\n",
    ")\n",
    "history = model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=32),\n",
    "    epochs=100,\n",
    "    validation_data=(X_val, y_val)\n",
    ")\n",
    "\n",
    "loss, accuracy = model.evaluate(X_train, y_train)\n",
    "print(f\"Train Accuracy: {accuracy * 100:.2f}%\")\n",
    "loss, accuracy = model.evaluate(X_train, y_train)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history.get('val_loss')  # Will exist if validation data is used\n",
    "# Plot the loss\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(loss, label='Training Loss')\n",
    "\n",
    "if val_loss:\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182c2ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex model (CNN architecture) with real-time data augmentation\n",
    "# (80%, 10%, 10%)\n",
    "X_train, y_train, X_temp, y_temp = create_train_test_split(splitXbyClass(X_raw, y_raw), train_ratio=0.8)\n",
    "X_val, y_val, X_test, y_test = create_train_test_split(splitXbyClass(X_temp, y_temp), train_ratio=0.5)\n",
    "X_train = X_train.reshape(X_train.shape[0], 64, 64, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], 64, 64, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 64, 64, 1)\n",
    "\n",
    "datagen = None\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,         # More aggressive rotation for varied gestures\n",
    "    width_shift_range=0.1,     # Increased shift for robust spatial understanding\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,           # More aggressive shear\n",
    "    zoom_range=0.25,            # Increased zoom for scalability\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    # First Convolutional Layer\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    # Second Convolutional Layer\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    # Flatten the 2D outputs to 1D for the Dense layers\n",
    "    Flatten(),\n",
    "\n",
    "    # Fully Connected Layer\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    # Output Layer for 10 classes\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=32),\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1c0b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_train, y_train)\n",
    "print(f\"Train Accuracy: {accuracy * 100:.2f}%\")\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Val Accuracy: {accuracy * 100:.2f}%\")\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history.get('val_loss')  # Will exist if validation data is used\n",
    "# Plot the loss\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(loss, label='Training Loss')\n",
    "\n",
    "if val_loss:\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix of the best Logistic Regression found\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "cm = confusion_matrix(y_test.ravel(), y_test_pred, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=range(10))\n",
    "disp.plot(cmap=plt.cm.Blues, values_format=\".0%\")\n",
    "plt.show()\n",
    "\n",
    "# print miss labeled images\n",
    "misclassified_indices = np.where(y_test.ravel() != y_test_pred)\n",
    "for i in misclassified_indices[0]:\n",
    "    pltImage(X_test[i], title=str(y_test_pred[i]) + \" != \" + str(y_test.ravel()[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d736e3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# miss predicted images\n",
    "X_train, y_train, X_test, y_test = create_train_test_split(splitXbyClass(X_raw, y_raw), train_ratio=0.8)\n",
    "\n",
    "a = splitXbyClass(X_raw, y_raw)\n",
    "pltImage([i[0] for i in a], grid=(1,10), figsize=(10,10))\n",
    "\n",
    "a = splitXbyClass(X_train, y_train)\n",
    "pltImage([i[0] for i in a], grid=(1,10), figsize=(10,10))\n",
    "\n",
    "a = splitXbyClass(X_test, y_test)\n",
    "pltImage([i[0] for i in a], grid=(1,10), figsize=(10,10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
